<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Carter Portwood</title>
    <link>/post/</link>
    <description>Recent content in Posts on Carter Portwood</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Getting Better Binomial Confidence Intervals</title>
      <link>/2020/10/01/getting-better-binomial-confidence-intervals/</link>
      <pubDate>Thu, 01 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/01/getting-better-binomial-confidence-intervals/</guid>
      <description>In a prior post, I showed how to compare expected interval lengths and coverages. In this post, I’ll show how you can leverage your prior knowledge to get better binomial confidence intervals.
When constructing a binomial confidence interval, it’s rare that one has no prior information about what the proportion of interest is. For instance, even if I know nothing about the proportion of defects at a factory, for most factories, I can safely assume that it’s more likely to be 10% than it is to be 90%.</description>
    </item>
    
    <item>
      <title>Visualizing Inspection Sampling Scheme Selection with &#39;gganimate&#39;</title>
      <link>/2020/09/06/visualizing-inspection-sampling-scheme-selection-with-gganimate/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/06/visualizing-inspection-sampling-scheme-selection-with-gganimate/</guid>
      <description>It’s common in the world of quality inspection to assess the proportion of defects produced by a process. To accept or reject a lot, acceptance sampling is often used. For a binary outcome like defect/not defect, this can take the form of randomly sampling \(n\) items and counting the number of defects, \(x\). The lot or process passes if \(x \le c\) and is rejected otherwise, where \(c\) is the maximum number of allowable defects.</description>
    </item>
    
    <item>
      <title>Comparing Binomial Confidence Interval Methods</title>
      <link>/2020/09/04/comparing-binomial-confidence-interval-methods/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/04/comparing-binomial-confidence-interval-methods/</guid>
      <description>Binomial Confidence Intervals Are Not Simple Sometimes it can be easy to take confidence intervals for granted. They’re one of the first things you learn in statistics, and you see them everywhere. We’re so used to \(\hat{\theta} \pm 1.96 \ \hat{se}(\hat{\theta})\) that it can be surprising that something as fundamental as binomial confidence intervals is still a subject of debate and confusion. In this post, I’ll discuss some ways you can compare confidence interval methods for binomial proportions with the easy-to-use binom package in R.</description>
    </item>
    
    <item>
      <title>MAD Outlier Detection</title>
      <link>/1/01/01/mad-outlier-detection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/mad-outlier-detection/</guid>
      <description>In this post, I show how to set the cutoff for MAD-based outlier detection. This is not meant to be an explainer about MAD outlier detection since there’s already good resources (here)[] and (here)[].
A colleague recent came to me asking for advice about automated univarite outlier detection. I wasn’t all that familiar with outlier detection. After doing some reading, I found a method that suited our purposes well: outlier detection using the Median Absolute Deviation (MAD).</description>
    </item>
    
  </channel>
</rss>