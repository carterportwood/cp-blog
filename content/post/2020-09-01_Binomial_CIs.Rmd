---
title: Comparing Binomial Confidence Interval Methods
author: Carter Portwood
date: '2020-09-04'
tags:
  - R
  - statistics
  - confidence intervals
  - binomial distribution
  - binom
output: html_document
---


```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

# Binomial Confidence Intervals Are Not Simple

Sometimes it can be easy to take confidence intervals for granted. They're one of the first things you learn in statistics, and you see them everywhere. We're so used to $\hat{\theta} \pm 1.96 \ \hat{se}(\hat{\theta})$ that it can be surprising that something as fundamental as binomial confidence intervals is still a subject of debate and confusion. In this post, I'll discuss some ways you can compare confidence interval methods for binomial proportions with the easy-to-use `binom` package in R.

# Say "no" to Wald

So first things first: the binomial confidence interval method you probably learned in high school, the Wald interval, $\hat{p} \pm 1.96 \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ (a.k.a. the normal approximation), should never be your method of choice. It's terrible. There's basically always a better method to choose. And with the ready availability of other methods already implemented (`binom` package in R, `scipy.statsmodels.proportion` module in Python), you have no excuse. That is, unless you're doing stats on a desert island. But even then, tedious calculations could help pass the time.

# How to choose a method? 

Okay, so the Wald interval is out. But now what? In this post, I'll consider the Wilson, Agresti-Coull, Jeffreys', and  Clopper-Pearson methods. In their seminal paper on this topic, Brown, Cai, and DasGupta recommend Wilson, Agresti-Coull, and Jeffreys'. And I include Clopper-Pearson because it is widely used. As a note, Jeffreys' is Bayesian with an uninformative prior, and Clopper-Pearson is often referred to as the 'exact' method.

There are two factors to evaluate for confidence intervals: coverage and length. Ideally, coverage is exactly $1-\alpha$, but because of the discrete nature of the binomial distribution, this isn't the case. Length is the expected length of the interval, the smaller the better. Both are functions of $n$ and $p$.

Let's plot the coverage and length for the four methods. 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
binom_zero_confint = function(x, n, conf.level) {
  alpha = 1 - conf.level
  if (x==0) {
    alpha = alpha*1.2
  }
  ci = binom.exact(x, n, conf.level = (1-alpha))
  ci$method = 'zero.mod'
  return(ci)
}


p = seq(0,0.5,0.00)
n = c(50)
binom.coverage(p, n, method=binom_zero_confint) %>%
  rbind(binom.coverage(p, n, method=c('exact', 'agresti-coull'))) %>%
  ggplot(aes(x=p, y=coverage, color=method)) + geom_line() + facet_wrap(vars(n))

#binom.length(0.05, 20, method=binom_zero_confint, conf.level=0.95)
#binom.length(0.05, 20, method='agresti-coull', conf.level=0.95)
```

```{r fig.dim=c(8.5,5.5), message=FALSE, warning=FALSE}
library(tidyverse)
library(binom)

p = seq(0,0.5,0.005)
n = c(8, 15, 50)
methods = c('agresti-coull', 'bayes', 'wilson', 'exact')

coverage = binom.coverage(p, n, method = methods, type='central')
len = binom.length(p, n, method = methods, type='central')

coverage = coverage %>%
  left_join(len, by=c('method', 'n', 'p'))

p1 = coverage %>%
  ggplot(aes(x=p, y=length, color=method)) + 
  geom_line() + 
  facet_wrap(vars(n), scales="free_y", labeller = label_both) +
  theme_minimal()

p2 = coverage %>%
  ggplot(aes(x=p, y=coverage, color=method)) + 
  geom_line(alpha=0.5, lwd=1) + 
  geom_hline(yintercept=0.95, lty=2, alpha=0.5) + 
  facet_wrap(vars(n), labeller = label_both) + ylim(0.825, 1.0) +
  theme_minimal()

gridExtra::grid.arrange(p1, p2, ncol=1)
```

We can see that the exact interval is the only that has coverage greater than 95% for all $p$. But it's also tends to be wider than the other methods. The Jeffreys' interval (shown as Bayes above) has inadequate coverage for some $p$ and $n$, but is quite narrow and has decent coverage for most $p$.

As noted by Brown *et al.*, the Agresti-Coull interval will always contain the Wilson interval, so it has both greater coverage and length for all $n$, $p$. For small $n$ in particular, Agresti-Coull is overly-conservative.

So we see the origin of Brown *et al.*'s guidance: Wilson or Jeffreys' for $n \le 40$ and Agresti-Coull for $n \gt 40$.

Hopefully you can use this code to evaluate interval methods for your particular situation. This code can also be found on my [GitHub]()

# References

1. Interval Estimation for a Binomial Proportion. Lawrence D. Brown, T. Tony Cai and Anirban DasGupta

1. Sundar Dorai-Raj (2014). binom: Binomial Confidence Intervals For Several
  Parameterizations. R package version 1.1-1. https://CRAN.R-project.org/package=binom




